{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perovskite Material Analysis and Band Gap Prediction\n",
    "\n",
    "This notebook documents the workflow for analyzing perovskite material compositions and predicting their band gaps using machine learning models. The steps include data cleaning, feature extraction, and model training with Ridge Regression and Random Forest Regressor. Our methodology was designed to allow us to reproduce findings from the Hussain et al paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preparation\n",
    "\n",
    "In this section, we load a sample dataset and perform data cleaning and preparation. The steps include:\n",
    "1. Loading the dataset into a pandas DataFrame.\n",
    "2. Cleaning and normalizing molecule names.\n",
    "3. Converting coefficients to floats.\n",
    "4. Extracting ions and coefficients into dictionaries.\n",
    "5. Identifying unique molecules and creating new columns for each unique molecule.\n",
    "6. Calculating the proportions for each molecule and assigning them to the corresponding columns.\n",
    "7. Dropping the original ion and coefficient columns as they are no longer needed.\n",
    "8. Saving the cleaned and modified DataFrame to a new CSV file.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:5: DtypeWarning: Columns (10,22,29,31,32,35,36,40,44,45,46,48,51,54,65,84,89,90,93,98,99,100,105,108,115,118,122,123,125,130,134,138,142,143,144,146,149,152,163,166,167,171,172,173,175,178,181,192,194,225,271,272,273,277,304,315,321,325,330,331,335,336,342,348,369,371,373,374,376,380,384,387,403,405,407,409) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path)\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned.dropna(subset=[\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\2672202543.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Unique molecules identified: {'MA', 'GA', 'Br', 'ALA', 'Ba', '3-Pr(NH3)2', 'IM', 'TMA', 'PDMA', 'FA', 'Mg', 'Na', 'Ti', 'OdA', 'CPEA', 'ThMA', 'Cs', 'GU', 'Ni', '1', 'CHMA', 'SCN', 'THM', 'A43', 'Br-PEA', 'BIM', 'Te', 'TFEA', 'OA', 'C8H17NH3', 'PEI', 'Cl-PEA', 'C4H9NH3', 'TBA', 'iso-BA', 'BYA', 'Au', 'I', 'TN', 'MIC1', 'PF6', 'HA', 'K', 'iPA', 'AVA', 'DMA', 'ODA', 'Ag', 'Ge', 'PR', 'Nb', 'oF1PEA', 'BA', 'HTAB', 'f-PEA', 'pF1PEA', 'PDA', 'PEA', 'F5PEA', 'Bi', 'Anyl', 'DI', 'Cl', 'Ca', 'Li', 'GABA', 'DA', 'FPEA', 'C4H9N2H6', 'EA', '3AMPY', 'Sb', 'Eu', 'APMim', 'BDA', '4FPEA', 'PA', 'BEA', 'BE', '3AMP', 'Hg', 'CH3ND3', 'Tb', 'Mn', 'C6H4NH2', '6-ACA', 'IA', 'EDA', 'BU', 'O', 'Rb', 'PBA', 'HEA', 'Sr', 'PTA', 'BI', 'Bn', 'MIC2', 'Aa', 'BzDA', 'HdA', 'Ada', 'CIEA', '5-AVAI', 'TA', 'Co', '4AMPY', 'Fe', 'DPA', 'BdA', 'PGA', 'n-C3H7NH3', 'FEA', 'EPA', 'BF4', 'Sn', '4ApyH', 'AN', 'HDA', 'HAD', 'EU-pyP', 'pFPEA', 'oFPEA', 'PPEA', 'DAT', 'TEA', 'CH3)3S', 'MTEA', 'IEA', 'PMA', 'PyEA', 'F-PEA', 'C6H13NH3', 'In', 'Cu', 'PN', 'H-PEA', 'Zn', 'BZA', 'Y', 'NMA', 'N-EtPy', 'Sm', 'mFPEA', 'Ace', 'La', 'Pb', 'PPA', 'DAP', 'S', '5-AVA', 'F3EA', 'NEA', 'MIC3', 'mF1PEA', 'NH4', 'CA'}\n",
      "Filtered Unique molecules identified: {'Sn', 'MA', 'FA', 'Cl', 'Br', 'Pb', 'I', 'Cs'}\n",
      "Remaining columns after dropping: Index(['JV_default_Voc', 'JV_default_Jsc', 'JV_default_FF', 'JV_default_PCE',\n",
      "       'Perovskite_band_gap', 'MA', 'Br', 'FA', 'Cs', 'I', 'Cl', 'Sn', 'Pb'],\n",
      "      dtype='object')\n",
      "CSV file modified and saved as: modified_file.csv\n",
      "Unique molecules identified: {'MA', '3-Pr(NH3)2)', '(mF1PEA)', 'GA', 'Br', '(THM)', '(PTA)', 'Ba', 'IM', '(ThMA)', 'FA', 'Mg', '(BEA)', 'Na', '(HTAB)', '(NMA)', '(BYA)', 'Ti', '(FPEA)', 'Cs', 'GU', '(HdA)', 'Ni', '(DMA)', '(AVA)', 'SCN', '(5-AVA)', '(TBA)', 'Te', 'OA', '(HAD)', '(TEA)', 'Au', 'I', 'TN', '(PBA)', 'PF6', 'HA', 'K', 'Ag', 'Ge', 'PR', 'Nb', '(CPEA)', '(MTEA)', 'BA', '(BDA)', '(BIM)', '(pFPEA)', '(FEA)', 'PDA', 'PEA', '(MIC1)', '(BZA)', 'Bi', '(A43)', '(H-PEA)', '(DPA)', '(TMA)', '(EU-pyP)', '(Anyl)', 'DI', 'Cl', 'Ca', '(SCN)', 'Li', '(DAT)', 'DA', '(Ada)', '(CH3ND3)', '(TFEA)', 'EA', 'Sb', 'Eu', '(BF4)', '(6-ACA)', 'BDA', 'PA', '(APMim)', '(ALA)', 'BE', '(EPA)', '(Ace)', '(N-EtPy)', 'Hg', '(NEA)', 'Tb', 'Mn', '(OdA)', '(5-AVAI)', '(oFPEA)', '(PEI)', 'IA', '(pF1PEA)', 'EDA', '(4AMPY)', 'BU', 'O', 'Rb', '(PPEA)', '(PDA)', '(mFPEA)', 'Sr', '(GABA)', '(PMA)', 'Bn', '(DAP)', 'Aa', '(3AMP)', '(PF6)', '(BzDA)', 'TA', '(BdA)', '(Br-PEA)', 'Co', '(PyEA)', 'Fe', '(MIC3)', '(Cl-PEA)', 'Sn', '(PEA)', '(n-C3H7NH3)', 'AN', 'HDA', '(MIC2)', '(iPA)', '(4FPEA)', '(1', '(C6H13NH3)', '(oF1PEA)', '(CIEA)', '(ODA)', 'In', 'Cu', 'PN', '(CHMA)', '(PGA)', 'Zn', '(3AMPY)', 'Y', '(PPA)', 'Sm', '(HEA)', '(EDA)', '(F5PEA)', '(iso-BA)', '(C8H17NH3)', 'La', 'Pb', '(C4H9N2H6)', '(C4H9NH3)', '(C6H4NH2)', '(IEA)', 'S', '(f-PEA)', '(PDMA)', '(F-PEA)', 'CA', '(F3EA)', 'NEA', '(4ApyH)', '(NH4)', '(BI)', '((CH3)3S)'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "# Load the CSV file\n",
    "file_path = 'perovsite_database_query.csv'  # Change this to your actual file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Columns to keep from the dataset\n",
    "columns_to_keep = [\n",
    "    'JV_default_Voc', 'JV_default_Jsc', 'JV_default_FF', 'JV_default_PCE', \n",
    "    'Perovskite_band_gap', 'Perovskite_composition_a_ions', 'Perovskite_composition_a_ions_coefficients',\n",
    "    'Perovskite_composition_b_ions', 'Perovskite_composition_b_ions_coefficients',\n",
    "    'Perovskite_composition_c_ions', 'Perovskite_composition_c_ions_coefficients'\n",
    "]\n",
    "data_cleaned = data[columns_to_keep]\n",
    "\n",
    "# Drop rows with NaN values in important columns\n",
    "data_cleaned.dropna(subset=[\n",
    "    'Perovskite_composition_a_ions', 'Perovskite_composition_a_ions_coefficients',\n",
    "    'Perovskite_composition_b_ions', 'Perovskite_composition_b_ions_coefficients',\n",
    "    'Perovskite_composition_c_ions', 'Perovskite_composition_c_ions_coefficients'\n",
    "], inplace=True)\n",
    "\n",
    "# Remove rows where 'Perovskite_band_gap' contains '|'\n",
    "data_cleaned = data_cleaned[~data_cleaned['Perovskite_band_gap'].str.contains('|', na=False)]\n",
    "\n",
    "# Reset index after dropping rows\n",
    "data_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Function to clean and normalize molecule names\n",
    "def clean_molecule_name(name):\n",
    "    # Remove leading/trailing spaces and normalize space\n",
    "    name = name.strip()\n",
    "    \n",
    "    # Allow alphanumeric characters and hyphens; also preserve names in parentheses\n",
    "    name = re.sub(r'[^a-zA-Z0-9\\s\\-()]+', ' ', name)\n",
    "\n",
    "    # Replace multiple spaces with a single space and trim again\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    \n",
    "    # Split the string into individual molecule components based on spaces\n",
    "    elements = name.split()\n",
    "\n",
    "    # Include valid molecule names, allowing for bracketed entries\n",
    "    elements = [element for element in elements if element and \n",
    "                not element.replace('.', '', 1).isdigit()]\n",
    "\n",
    "    return elements\n",
    "\n",
    "# Function to clean and convert coefficients to floats\n",
    "def clean_and_convert_coefficient(coefficient):\n",
    "    try:\n",
    "        # Remove non-numeric characters except periods and minus signs\n",
    "        cleaned_coefficient = re.sub(r'[^0-9.-]', '', coefficient)\n",
    "        return float(cleaned_coefficient)\n",
    "    except ValueError:\n",
    "        return 0.0  # Default to 0.0 if conversion fails\n",
    "\n",
    "# Function to split ions and coefficients into dictionaries\n",
    "def extract_ions_and_coefficients(ions_column, coefficients_column):\n",
    "    # Split ions and coefficients by ';' and '|'\n",
    "    ions = re.split(r'[;|]', ions_column)\n",
    "    coefficients = re.split(r'[;|]', coefficients_column)\n",
    "    \n",
    "    # Clean and convert to floats\n",
    "    coefficients = [clean_and_convert_coefficient(c) for c in coefficients]\n",
    "    \n",
    "    # Clean ion names and split into individual elements\n",
    "    all_ions = []\n",
    "    for ion in ions:\n",
    "        cleaned_ions = clean_molecule_name(ion)  # Clean and split the ion names\n",
    "        all_ions.extend(cleaned_ions)            # Add each individual element\n",
    "    \n",
    "    return all_ions, coefficients\n",
    "\n",
    "# Step 1: Identify unique molecules\n",
    "unique_molecules = set()\n",
    "\n",
    "# Go through each row to identify unique ions\n",
    "for index, row in data_cleaned.iterrows():\n",
    "    for column_group in ['a', 'b', 'c']:\n",
    "        ions_column = f'Perovskite_composition_{column_group}_ions'\n",
    "        coefficients_column = f'Perovskite_composition_{column_group}_ions_coefficients'\n",
    "        \n",
    "        ions = str(row[ions_column]).split(';')\n",
    "        all_ions = []\n",
    "        for ion in ions:\n",
    "            cleaned_ions = clean_molecule_name(ion)\n",
    "            all_ions.extend(cleaned_ions)\n",
    "        unique_molecules.update(all_ions)\n",
    "\n",
    "# Remove any 'nan' from unique molecules set\n",
    "unique_molecules.discard('nan')\n",
    "\n",
    "# Step 2: Create new columns for each unique molecule\n",
    "for molecule in unique_molecules:\n",
    "    data_cleaned[molecule] = 0.0  # Initialize columns for each molecule with 0.0\n",
    "\n",
    "# Step 3: Calculate the proportions for each molecule\n",
    "for index, row in data_cleaned.iterrows():\n",
    "    # Iterate over the ion columns and their coefficients\n",
    "    for column_group in ['a', 'b', 'c']:\n",
    "        ions_column = f'Perovskite_composition_{column_group}_ions'\n",
    "        coefficients_column = f'Perovskite_composition_{column_group}_ions_coefficients'\n",
    "        \n",
    "        ions, coefficients = extract_ions_and_coefficients(str(row[ions_column]), str(row[coefficients_column]))\n",
    "\n",
    "        total_coeff = sum(coefficients) if sum(coefficients) != 0 else 1  # Avoid division by zero\n",
    "        \n",
    "        # Calculate proportion and assign to the corresponding molecule columns\n",
    "        for ion, coeff in zip(ions, coefficients):\n",
    "            data_cleaned.at[index, ion] += coeff / total_coeff  # Add the proportion to the column\n",
    "\n",
    "# Step 4: Drop the original ion and coefficient columns as they are no longer needed\n",
    "columns_to_drop = [\n",
    "    'Perovskite_composition_a_ions', 'Perovskite_composition_a_ions_coefficients',\n",
    "    'Perovskite_composition_b_ions', 'Perovskite_composition_b_ions_coefficients',\n",
    "    'Perovskite_composition_c_ions', 'Perovskite_composition_c_ions_coefficients'\n",
    "]\n",
    "data_cleaned.drop(columns=columns_to_drop, inplace=True)\n",
    "# Remove brackets from molecule names in the unique molecules set\n",
    "unique_molecules_cleaned = {molecule.strip('()') for molecule in unique_molecules}\n",
    "\n",
    "# Update the output to show the cleaned unique molecules\n",
    "print(\"Cleaned Unique molecules identified:\", unique_molecules_cleaned)\n",
    "\n",
    "# Filter the unique molecules set to keep only the specified molecules\n",
    "molecules_to_keep = {'I', 'Br', 'Pb', 'Sn', 'Cl', 'FA', 'MA', 'Cs'}\n",
    "filtered_unique_molecules = unique_molecules.intersection(molecules_to_keep)\n",
    "\n",
    "# Update the output to show the filtered unique molecules\n",
    "print(\"Filtered Unique molecules identified:\", filtered_unique_molecules)\n",
    "\n",
    "\n",
    "\n",
    "# Drop all columns in data_cleaned that are not in molecules_to_keep\n",
    "columns_to_drop = [col for col in data_cleaned.columns if col not in molecules_to_keep and col not in columns_to_keep]\n",
    "data_cleaned.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "\n",
    "# Update the output to show the remaining columns\n",
    "print(\"Remaining columns after dropping:\", data_cleaned.columns)\n",
    "# Save the modified dataframe to a new CSV\n",
    "output_file_path = 'modified_file.csv'\n",
    "data_cleaned.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"CSV file modified and saved as:\", output_file_path)\n",
    "print(\"Unique molecules identified:\", unique_molecules)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next part, we train and test different ML models (identical to those used in the Hussain et al paper) on the cleaned perovskite database. Following this, we predict values of band gap and PCE and compare the error between these predictions and real values seen in the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR performance:\n",
      "Mean absolute error: 0.02538766020300304\n",
      "Mean square error: 0.00311387569708245\n",
      "R2 Score: 0.7726241732513978\n",
      "\n",
      "RR performance:\n",
      "Mean absolute error: 0.025500870187326486\n",
      "Mean square error: 0.003147480517194903\n",
      "R2 Score: 0.770170342559644\n",
      "\n",
      "KNN performance:\n",
      "Mean absolute error: 0.023537444146559446\n",
      "Mean square error: 0.0030909265272564797\n",
      "R2 Score: 0.7742999262261434\n",
      "\n",
      "RF performance:\n",
      "Mean absolute error: 0.017787095906210037\n",
      "Mean square error: 0.0020605546339697712\n",
      "R2 Score: 0.8495378881377568\n",
      "\n",
      "XGBoost performance:\n",
      "Mean absolute error: 0.017895967415851442\n",
      "Mean square error: 0.0020297801201198495\n",
      "R2 Score: 0.8517850492996388\n",
      "\n",
      "       Actual  LR_Predicted  RR_Predicted  KNN_Predicted  RF_Predicted  \\\n",
      "9004      1.6      1.591892      1.591924           1.61       1.59463   \n",
      "36140     1.6      1.605958      1.606303           1.59       1.59100   \n",
      "25301     1.6      1.591443      1.591481           1.56       1.59610   \n",
      "26083     1.6      1.599469      1.599686           1.60       1.59890   \n",
      "25156     1.6      1.608755      1.609137           1.60       1.59550   \n",
      "\n",
      "       XGBoost_Predicted  \n",
      "9004            1.593001  \n",
      "36140           1.593906  \n",
      "25301           1.591196  \n",
      "26083           1.594912  \n",
      "25156           1.589133  \n"
     ]
    }
   ],
   "source": [
    "###### CRISTINA TEST\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('modified_file.csv')\n",
    "\n",
    "# Remove rows with NaN values (including np.nan)\n",
    "data = data.dropna()  # This drops rows with any NaN values\n",
    "\n",
    "# Prepare features and targets\n",
    "\n",
    "# For prediction of each target variable y (Voc, Jsc, FF, PCE and band gap), we want X to exclude/drop that specific target variable, \n",
    "# but include the other (4) \"y's\" (and all other features/molecules), dont want to include certain feature in prediction of itself\n",
    "\n",
    "# For band gap prediction\n",
    "X = data.drop(['Perovskite_band_gap'], axis=1)\n",
    "y_band_gap = data['Perovskite_band_gap']\n",
    "# Split the data\n",
    "X_train, X_test, y_band_gap_train, y_band_gap_test = train_test_split(X, y_band_gap, test_size=0.2, random_state=42)\n",
    "# Initialise models \n",
    "models = {\n",
    "    'LR': LinearRegression(),\n",
    "    'RR': Ridge(),\n",
    "    'KNN': KNeighborsRegressor(),\n",
    "    'RF': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# train and evaluate models\n",
    "results = {}\n",
    "y_band_gap_pred = {}\n",
    "\n",
    "######### CONTINUE HERE, check this\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "y_band_gap_pred = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_band_gap_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_band_gap_pred[name] = y_pred\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mae = mean_absolute_error(y_band_gap_test, y_pred)\n",
    "    mse = mean_squared_error(y_band_gap_test, y_pred)\n",
    "    r2 = r2_score(y_band_gap_test, y_pred)\n",
    "    \n",
    "    # Store the results in a dictionary\n",
    "    results[name] = {\n",
    "        'Mean absolute error': mae,\n",
    "        'Mean square error': mse,\n",
    "        'R2 Score': r2\n",
    "    }\n",
    "\n",
    "# Print the results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name} performance:\")\n",
    "    print(f\"Mean absolute error: {metrics['Mean absolute error']}\")\n",
    "    print(f\"Mean square error: {metrics['Mean square error']}\")\n",
    "    print(f\"R2 Score: {metrics['R2 Score']}\\n\")\n",
    "\n",
    "# Display predictions for band gap for each of the models\n",
    "\n",
    "# Create a DataFrame to store the actual and predicted values\n",
    "predictions_df = pd.DataFrame(y_band_gap_test.values, columns=['Actual'], index=y_band_gap_test.index)\n",
    "# Add a title to the DataFrame\n",
    "predictions_df.style.set_caption(\"Band Gap Predictions for Different ML Models\")\n",
    "\n",
    "# Add the predictions for each model to the DataFrame\n",
    "for name, y_pred in y_band_gap_pred.items():\n",
    "    predictions_df[name + '_Predicted'] = y_pred\n",
    "\n",
    "# Display the first few rows of the DataFrame to see the results\n",
    "print(predictions_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\1732292398.py:41: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r_value = np.sqrt(r2_score(y_true, y_pred))\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\1732292398.py:41: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r_value = np.sqrt(r2_score(y_true, y_pred))\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\1732292398.py:41: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r_value = np.sqrt(r2_score(y_true, y_pred))\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\1732292398.py:41: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r_value = np.sqrt(r2_score(y_true, y_pred))\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\1732292398.py:41: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r_value = np.sqrt(r2_score(y_true, y_pred))\n",
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_31644\\1732292398.py:41: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r_value = np.sqrt(r2_score(y_true, y_pred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Models  Band gap prediction r-Value  Band gap prediction RMSE (eV)  \\\n",
      "0       LR                     0.874396                       0.056782   \n",
      "1       RR                     0.872853                       0.057106   \n",
      "2      KNN                     0.913284                       0.047667   \n",
      "3       RF                     0.924299                       0.044665   \n",
      "4  XGBoost                     0.924254                       0.044677   \n",
      "\n",
      "   PCE direct prediction r-Value  PCE direct prediction RMSE (%)  \\\n",
      "0                       0.365757                        4.651490   \n",
      "1                       0.365795                        4.651415   \n",
      "2                            NaN                        5.206572   \n",
      "3                       0.413458                        4.550596   \n",
      "4                       0.415590                        4.545743   \n",
      "\n",
      "   PCE calculated r-Value  PCE calculated RMSE (%)  \n",
      "0                     NaN                12.532712  \n",
      "1                     NaN                12.532723  \n",
      "2                     NaN                12.506284  \n",
      "3                     NaN                12.531758  \n",
      "4                     NaN                12.531737  \n",
      "Table 1 with results has been generated and saved as 'table_1_results.png'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('modified_file.csv')\n",
    "\n",
    "# Remove rows with NaN values (including np.nan)\n",
    "data = data.dropna()  # This drops rows with any NaN values\n",
    "\n",
    "# Prepare features and targets\n",
    "\n",
    "# For prediction of each target variable y (Voc, Jsc, FF, PCE and band gap), we want X to exclude/drop that specific target variable, \n",
    "# but include the other (4) \"y's\" (and all other features/molecules)\n",
    "\n",
    "X = data.drop(['JV_default_Voc', 'JV_default_Jsc', 'JV_default_FF', 'JV_default_PCE', 'Perovskite_band_gap'], axis=1)\n",
    "y_band_gap = data['Perovskite_band_gap']\n",
    "y_pce = data['JV_default_PCE']\n",
    "y_voc = data['JV_default_Voc']\n",
    "y_jsc = data['JV_default_Jsc']\n",
    "y_ff = data['JV_default_FF']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_band_gap_train, y_band_gap_test, y_pce_train, y_pce_test, \\\n",
    "y_voc_train, y_voc_test, y_jsc_train, y_jsc_test, y_ff_train, y_ff_test = \\\n",
    "    train_test_split(X, y_band_gap, y_pce, y_voc, y_jsc, y_ff, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'LR': LinearRegression(),\n",
    "    'RR': Ridge(),\n",
    "    'KNN': KNeighborsRegressor(),\n",
    "    'RF': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    r_value = np.sqrt(r2_score(y_true, y_pred))\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    return r_value, rmse\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {model_name: {'Band gap prediction': [], 'PCE direct prediction': [], 'PCE calculated': []}\n",
    "           for model_name in models.keys()}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Band gap prediction\n",
    "    model.fit(X_train, y_band_gap_train)\n",
    "    y_band_gap_pred = model.predict(X_test)\n",
    "    r_value, rmse = evaluate_model(y_band_gap_test, y_band_gap_pred)\n",
    "    results[model_name]['Band gap prediction'] = [r_value, rmse]\n",
    "\n",
    "    # PCE direct prediction\n",
    "    model.fit(X_train, y_pce_train)\n",
    "    y_pce_pred = model.predict(X_test)\n",
    "    r_value, rmse = evaluate_model(y_pce_test, y_pce_pred)\n",
    "    results[model_name]['PCE direct prediction'] = [r_value, rmse]\n",
    "\n",
    "    # Train models for Voc, Jsc, and FF\n",
    "    model.fit(X_train, y_voc_train)\n",
    "    y_voc_pred = model.predict(X_test)\n",
    "    model.fit(X_train, y_jsc_train)\n",
    "    y_jsc_pred = model.predict(X_test)\n",
    "    model.fit(X_train, y_ff_train)\n",
    "    y_ff_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate PCE from predicted Voc, Jsc, and FF\n",
    "    # NOTE: need to add a column for 'real' calculated PCE in the dataset (to avoid nan r values)?\n",
    "    power_in = 100   # subject to change\n",
    "    y_pce_calculated = y_voc_pred * y_jsc_pred * y_ff_pred / power_in\n",
    "    r_value, rmse = evaluate_model(y_pce_test, y_pce_calculated)\n",
    "    results[model_name]['PCE calculated'] = [r_value, rmse]\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "df_results = pd.DataFrame({\n",
    "    'Models': list(models.keys()),\n",
    "    'Band gap prediction r-Value': [results[model]['Band gap prediction'][0] for model in models],\n",
    "    'Band gap prediction RMSE (eV)': [results[model]['Band gap prediction'][1] for model in models],\n",
    "    'PCE direct prediction r-Value': [results[model]['PCE direct prediction'][0] for model in models],\n",
    "    'PCE direct prediction RMSE (%)': [results[model]['PCE direct prediction'][1] for model in models],\n",
    "    'PCE calculated r-Value': [results[model]['PCE calculated'][0] for model in models],\n",
    "    'PCE calculated RMSE (%)': [results[model]['PCE calculated'][1] for model in models]\n",
    "})\n",
    "\n",
    "# Display the results\n",
    "print(df_results)\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.axis('off')\n",
    "\n",
    "# Create the table\n",
    "table = ax.table(cellText=df_results.values,\n",
    "                 colLabels=df_results.columns,\n",
    "                 cellLoc='center',\n",
    "                 loc='center')\n",
    "\n",
    "# Set table properties\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1.2, 1.5)\n",
    "\n",
    "# Add title\n",
    "plt.title(\"Table 1: ML model types with corresponding results\", fontsize=12, fontweight='bold', pad=20)\n",
    "\n",
    "# Save the figure\n",
    "plt.tight_layout()\n",
    "plt.savefig('table_1_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"Table 1 with results has been generated and saved as 'table_1_results.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure 4 with results has been generated and saved as 'figure_4_results.png'\n",
      "Ridge Regression Feature Importance:\n",
      "  feature  importance\n",
      "5      Cl    0.270267\n",
      "1      Br    0.216369\n",
      "6      Sn    0.182374\n",
      "2      FA    0.116853\n",
      "0      MA    0.083122\n",
      "7      Pb    0.072064\n",
      "3      Cs    0.047017\n",
      "4       I    0.011934\n",
      "\n",
      "Random Forest Feature Importance:\n",
      "  feature  importance\n",
      "4       I    0.583427\n",
      "6      Sn    0.118893\n",
      "7      Pb    0.101370\n",
      "1      Br    0.070698\n",
      "2      FA    0.048938\n",
      "3      Cs    0.036947\n",
      "0      MA    0.029220\n",
      "5      Cl    0.010508\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('modified_file.csv')\n",
    "# Remove rows with NaN values (including np.nan)\n",
    "data = data.dropna()  # This drops rows with any NaN values\n",
    "\n",
    "# Prepare features and target\n",
    "X = data.drop(['JV_default_Voc', 'JV_default_Jsc', 'JV_default_FF', 'JV_default_PCE', 'Perovskite_band_gap'], axis=1)\n",
    "y = data['Perovskite_band_gap']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Ridge Regression model\n",
    "rr_model = Ridge()\n",
    "rr_model.fit(X_train, y_train)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance for Ridge Regression\n",
    "rr_importance = np.abs(rr_model.coef_)\n",
    "rr_importance = rr_importance / np.sum(rr_importance)\n",
    "rr_feature_importance = pd.DataFrame({'feature': X.columns, 'importance': rr_importance})\n",
    "rr_feature_importance = rr_feature_importance.sort_values('importance', ascending=False).head(8)\n",
    "\n",
    "# Get feature importance for Random Forest\n",
    "rf_importance = rf_model.feature_importances_\n",
    "rf_feature_importance = pd.DataFrame({'feature': X.columns, 'importance': rf_importance})\n",
    "rf_feature_importance = rf_feature_importance.sort_values('importance', ascending=False).head(8)\n",
    "\n",
    "# Create subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot for RR model\n",
    "ax1.barh(rr_feature_importance['feature'], rr_feature_importance['importance'], color='steelblue', height=0.6)\n",
    "ax1.set_xlabel('Impact')\n",
    "ax1.set_title('(a) RR model')\n",
    "ax1.invert_yaxis()  # Invert y-axis to match the image\n",
    "\n",
    "# Plot for RF model\n",
    "ax2.barh(rf_feature_importance['feature'], rf_feature_importance['importance'], color='steelblue', height=0.6)\n",
    "ax2.set_xlabel('Impact')\n",
    "ax2.set_title('(b) RF model')\n",
    "ax2.invert_yaxis()  # Invert y-axis to match the image\n",
    "\n",
    "# Add overall title\n",
    "fig.suptitle('Fig. 4 Impact of different materials on band gap prediction', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Adjust layout and save\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure_4_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"Figure 4 with results has been generated and saved as 'figure_4_results.png'\")\n",
    "\n",
    "# Print feature importances\n",
    "print(\"Ridge Regression Feature Importance:\")\n",
    "print(rr_feature_importance)\n",
    "print(\"\\nRandom Forest Feature Importance:\")\n",
    "print(rf_feature_importance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
