{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perovskite modelling program - returning PSC stack from an input row (from perovskite database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing our dataframe to have columns for individual elements, with a normalised coefficient and site for each\n",
    "1. Initital cleaning of ions and coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_22972\\215694299.py:8: DtypeWarning: Columns (10,22,29,31,32,35,36,40,44,45,46,48,51,54,65,84,89,90,93,98,99,100,105,108,115,118,122,123,125,130,134,138,142,143,144,146,149,152,163,166,167,171,172,173,175,178,181,192,194,225,271,272,273,277,304,315,321,325,330,331,335,336,342,348,369,371,373,374,376,380,384,387,403,405,407,409) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset with index saved as filtered_DatabaseMaterials_with_index.csv\n",
      "Unchanged ion data saved as ion_data_unchanged.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_22972\\215694299.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ion_data[col] = ion_data[col].apply(normalize_coefficients)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'perovskite_composition_a_ions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\c\\miniconda3\\envs\\test-env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'perovskite_composition_a_ions'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 98\u001b[0m\n\u001b[0;32m     96\u001b[0m     coefficients_column \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperovskite_composition_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn_group\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_ions_coefficients\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m ion_data\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m---> 98\u001b[0m         ions, _ \u001b[38;5;241m=\u001b[39m clean_molecule_name(\u001b[38;5;28mstr\u001b[39m(\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mions_column\u001b[49m\u001b[43m]\u001b[49m)), [clean_and_convert_coefficient(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(row[coefficients_column])\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m     99\u001b[0m         unique_molecules\u001b[38;5;241m.\u001b[39mupdate(ions)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Create columns for each unique molecule and calculate proportions\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\c\\miniconda3\\envs\\test-env\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\c\\miniconda3\\envs\\test-env\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\c\\miniconda3\\envs\\test-env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'perovskite_composition_a_ions'"
     ]
    }
   ],
   "source": [
    "\n",
    "##### Final cleaned and split dataset \n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = r\"C:\\Users\\c\\Documents\\PEROVSKITE PROJECT\\PerovskiteML_project\\Data\\Perovsite database query.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Define the columns to keep\n",
    "columns_to_keep = [\n",
    "    'Cell_stack_sequence', 'Cell_architecture',\n",
    "    'Substrate_stack_sequence', 'Substrate_thickness',\n",
    "    'ETL_stack_sequence', 'ETL_thickness', 'ETL_additives_compounds', 'ETL_additives_concentrations',\n",
    "    'Perovskite_composition_a_ions', 'Perovskite_composition_a_ions_coefficients', \n",
    "    'Perovskite_composition_b_ions', 'Perovskite_composition_b_ions_coefficients',\n",
    "    'Perovskite_composition_c_ions', 'Perovskite_composition_c_ions_coefficients', \n",
    "    'Perovskite_additives_compounds', 'Perovskite_additives_concentrations', 'Perovskite_thickness',\n",
    "    'HTL_stack_sequence', 'HTL_thickness_list', 'HTL_additives_compounds', 'HTL_additives_concentrations',\n",
    "    'Backcontact_stack_sequence', 'Backcontact_thickness', \n",
    "    'Backcontact_additives_compounds', 'Backcontact_additives_concentrations',\n",
    "    'Add_lay_front', 'Add_lay_front_function', 'Add_lay_front_stack_sequence', 'Add_lay_front_thickness_list', \n",
    "    'Add_lay_front_additives_compounds', 'Add_lay_front_additives_concentrations',\n",
    "    'Add_lay_back', 'Add_lay_back_function', 'Add_lay_back_stack_sequence', 'Add_lay_back_thickness_list', \n",
    "    'Add_lay_back_additives_compounds', 'Add_lay_back_additives_concentrations',\n",
    "    'Encapsulation', 'Encapsulation_stack_sequence'\n",
    "]\n",
    "\n",
    "# Filter columns to keep only those that exist in the dataset\n",
    "existing_columns = [col for col in columns_to_keep if col in data.columns]\n",
    "data = data[existing_columns]\n",
    "\n",
    "# Add an index column\n",
    "data.reset_index(inplace=True)\n",
    "data.rename(columns={'index': 'Index'}, inplace=True)\n",
    "\n",
    "# Save the filtered dataset to a new CSV file\n",
    "output_path = 'filtered_DatabaseMaterials_with_index.csv'\n",
    "data.to_csv(output_path, index=False)\n",
    "print(\"Filtered dataset with index saved as\", output_path)\n",
    "\n",
    "# Create a separate dataframe for ions and their coefficients\n",
    "ion_columns = [\n",
    "    'Perovskite_composition_a_ions', 'Perovskite_composition_a_ions_coefficients', \n",
    "    'Perovskite_composition_b_ions', 'Perovskite_composition_b_ions_coefficients',\n",
    "    'Perovskite_composition_c_ions', 'Perovskite_composition_c_ions_coefficients'\n",
    "]\n",
    "\n",
    "ion_data = data[ion_columns]\n",
    "\n",
    "# Save the unchanged ion data\n",
    "output_path = 'ion_data_unchanged.csv'\n",
    "ion_data.to_csv(output_path, index=False)\n",
    "print(\"Unchanged ion data saved as\", output_path)\n",
    "\n",
    "# Function to clean molecule names\n",
    "def clean_molecule_name(name):\n",
    "    name = re.sub(r'[^a-zA-Z0-9\\s\\-()]+', ' ', name.strip())\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    elements = [element for element in name.split() if element and not element.replace('.', '', 1).isdigit()]\n",
    "    return elements\n",
    "\n",
    "# Function to clean and convert coefficients to floats\n",
    "def clean_and_convert_coefficient(coefficient):\n",
    "    try:\n",
    "        cleaned_coefficient = re.sub(r'[^0-9.eE-]', '', coefficient.replace(',', '').strip())\n",
    "        return float(cleaned_coefficient) if cleaned_coefficient else 0.0\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "\n",
    "# Function to normalize coefficients\n",
    "def normalize_coefficients(cell):\n",
    "    if pd.notna(cell):\n",
    "        try:\n",
    "            coefficients = [float(x.strip()) for x in re.split(r'[;|]', cell) if x.strip()]\n",
    "            total_sum = sum(coefficients)\n",
    "            return ';'.join(f\"{val / total_sum:.3f}\" for val in coefficients) if total_sum > 0 else cell\n",
    "        except ValueError:\n",
    "            return cell\n",
    "    return cell\n",
    "\n",
    "# Normalize coefficients in each column\n",
    "coefficient_columns = [\n",
    "    'Perovskite_composition_a_ions_coefficients', \n",
    "    'Perovskite_composition_b_ions_coefficients', \n",
    "    'Perovskite_composition_c_ions_coefficients'\n",
    "]\n",
    "\n",
    "for col in coefficient_columns:\n",
    "    ion_data[col] = ion_data[col].apply(normalize_coefficients)\n",
    "\n",
    "# Create a set of unique molecules and add new columns\n",
    "unique_molecules = set()\n",
    "for column_group in ['a', 'b', 'c']:\n",
    "    ions_column = f'perovskite_composition_{column_group}_ions'\n",
    "    coefficients_column = f'perovskite_composition_{column_group}_ions_coefficients'\n",
    "    for _, row in ion_data.iterrows():\n",
    "        ions, _ = clean_molecule_name(str(row[ions_column])), [clean_and_convert_coefficient(c) for c in str(row[coefficients_column]).split(';')]\n",
    "        unique_molecules.update(ions)\n",
    "\n",
    "# Create columns for each unique molecule and calculate proportions\n",
    "for molecule in unique_molecules:\n",
    "    ion_data[molecule] = 0.0\n",
    "\n",
    "for index, row in data[coefficient_columns].iterrows():\n",
    "    for column_group in ['a', 'b', 'c']:\n",
    "        ions_column = f'perovskite_composition_{column_group}_ions'\n",
    "        coefficients_column = f'perovskite_composition_{column_group}_ions_coefficients'\n",
    "        ions = clean_molecule_name(str(row[ions_column]))\n",
    "        coefficients = [clean_and_convert_coefficient(c) for c in str(row[coefficients_column]).split(';')]\n",
    "        total_coeff = sum(coefficients) if sum(coefficients) != 0 else 1\n",
    "        \n",
    "        for ion, coeff in zip(ions, coefficients):\n",
    "            ion_data.at[index, ion] += coeff / total_coeff\n",
    "\n",
    "\n",
    "# Create a new column 'Layer_Type' to indicate if the row is multilayered or single-layered\n",
    "ion_data['Layer Type'] = ion_data.apply(\n",
    "    lambda row: 'Multi-layered Perovskite' if any('|' in str(row[col]) for col in ion_columns) else 'Single-layered Perovskite',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Drop the original ion columns as before\n",
    "ion_data = ion_data.drop(columns=ion_columns, errors='ignore')\n",
    "\n",
    "# Save the modified DataFrame with the 'Layer_Type' column\n",
    "output_file_path = 'modified_data_with_layer_type.csv'\n",
    "ion_data.to_csv(output_file_path, index=False)\n",
    "print(\"CSV file with layer type information modified and saved as:\", output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-zero entries in row 1234: {'Index': np.int64(1234), 'Cell_stack_sequence': 'SLG | FTO | TiO2-c | TiO2-mp | Perovskite | Spiro-MeOTAD | Au', 'Cell_architecture': 'nip', 'Substrate_stack_sequence': 'SLG | FTO', 'Substrate_thickness': nan, 'ETL_stack_sequence': 'TiO2-c | TiO2-mp', 'ETL_thickness': '20.0 | 150.0', 'ETL_additives_compounds': 'Li-TFSI; Mg(TFSI)2', 'ETL_additives_concentrations': nan, 'Perovskite_composition_a_ions': 'Cs; FA; MA', 'Perovskite_composition_a_ions_coefficients': '0.050;0.750;0.200', 'Perovskite_composition_b_ions': 'Pb', 'Perovskite_composition_b_ions_coefficients': '1.000', 'Perovskite_composition_c_ions': 'I', 'Perovskite_composition_c_ions_coefficients': '1.000', 'Perovskite_additives_compounds': 'KI', 'Perovskite_additives_concentrations': nan, 'Perovskite_thickness': 500.0, 'HTL_stack_sequence': 'Spiro-MeOTAD', 'HTL_thickness_list': nan, 'HTL_additives_compounds': 'Co; Li-TFSI; TBP', 'HTL_additives_concentrations': nan, 'Backcontact_stack_sequence': 'Au', 'Backcontact_additives_compounds': nan, 'Backcontact_additives_concentrations': nan, 'Add_lay_front_function': nan, 'Add_lay_front_stack_sequence': 'Unknown', 'Add_lay_front_thickness_list': np.float64(nan), 'Add_lay_front_additives_compounds': np.float64(nan), 'Add_lay_front_additives_concentrations': np.float64(nan), 'Add_lay_back_function': nan, 'Add_lay_back_stack_sequence': 'Unknown', 'Add_lay_back_thickness_list': np.float64(nan), 'Add_lay_back_additives_compounds': np.float64(nan), 'Add_lay_back_additives_concentrations': np.float64(nan), 'Encapsulation_stack_sequence': 'Unknown'}\n"
     ]
    }
   ],
   "source": [
    "# for a given row / perovskite, return all non-zero element and coefficient entries\n",
    "\n",
    "# Function to get non-zero cells for a specific row\n",
    "def get_non_zero_cells(row_number):\n",
    "    # Check if the row_number is valid\n",
    "    if row_number < 0 or row_number >= len(ion_data):\n",
    "        return \"Invalid row number\"\n",
    "    \n",
    "    # Get the specified row\n",
    "    row = ion_data.iloc[row_number]\n",
    "\n",
    "    # Find non-zero (non-empty) entries and their column names\n",
    "    non_zero_cells = {col: value for col, value in row.items() if value != 0 and value != ''}\n",
    "\n",
    "    return non_zero_cells\n",
    "\n",
    "# Example usage\n",
    "row_number = 1234 # Replace with the row number you want to check\n",
    "result = get_non_zero_cells(row_number)\n",
    "print(f\"Non-zero entries in row {row_number}: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hussain paper replication - formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Unique molecules identified: {'Cl', 'Pb', 'MA', 'Sn', 'FA', 'I', 'Cs', 'Br'}\n",
      "Remaining columns after dropping: Index(['Sn', 'Cs', 'MA', 'I', 'Cl', 'Br', 'Pb', 'FA'], dtype='object')\n",
      "CSV file modified and saved as: hussain_molecules_file.csv\n"
     ]
    }
   ],
   "source": [
    "# Filter the unique molecules set to keep only the specified molecules\n",
    "molecules_to_keep = {'I', 'Br', 'Pb', 'Sn', 'Cl', 'FA', 'MA', 'Cs'}\n",
    "filtered_unique_molecules = unique_molecules.intersection(molecules_to_keep)\n",
    "\n",
    "# Update the output to show the filtered unique molecules\n",
    "print(\"Filtered Unique molecules identified:\", filtered_unique_molecules)\n",
    "\n",
    "# Drop all columns in data_cleaned that are not in molecules_to_keep\n",
    "columns_to_drop = [col for col in ion_data.columns if col not in molecules_to_keep and col not in columns_to_keep]\n",
    "ion_data.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Update the output to show the remaining columns\n",
    "print(\"Remaining columns after dropping:\", ion_data.columns)\n",
    "\n",
    "# Save the modified dataframe to a new CSV\n",
    "output_file_path = 'hussain_molecules_file.csv'\n",
    "ion_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"CSV file modified and saved as:\", output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-format data into a dataframe we can easily vectorise to enable embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\AppData\\Local\\Temp\\ipykernel_22972\\2706600968.py:6: DtypeWarning: Columns (10,22,29,31,32,35,36,40,44,45,46,48,51,54,65,84,89,90,93,98,99,100,105,108,115,118,122,123,125,130,134,138,142,143,144,146,149,152,163,166,167,171,172,173,175,178,181,192,194,225,271,272,273,277,304,315,321,325,330,331,335,336,342,348,369,371,373,374,376,380,384,387,403,405,407,409) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r\"C:\\Users\\c\\Documents\\PEROVSKITE PROJECT\\PerovskiteML_project\\Data\\Perovsite database query.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  combined_ions combined_coefficients\n",
      "0       Cs,Sn,I                 1,1,3\n",
      "1   Cs,Sn,Br, I          1,1,0.3, 2.7\n",
      "2   Cs,Sn,Br, I          1,1,1.5, 1.5\n",
      "3   Cs,Sn,Br, I          1,1,2.7, 0.3\n",
      "4      Cs,Sn,Br                 1,1,3\n",
      "DataFrame with combined columns saved to combined_ions_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "## for each row - the code should be able to return values split into 3 different columns: a list of elements in the crystal, a list of their respective coefficients and sites\n",
    "# eg. for row 123: [MA, I, Pb, Br], [1,1,0.5,0.5], [a,b,c,c]\n",
    "\n",
    "# use original dataset\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\c\\Documents\\PEROVSKITE PROJECT\\PerovskiteML_project\\Data\\Perovsite database query.csv\")\n",
    "\n",
    "# replace all ; and | in ion columns data with ,\n",
    "# Replace all occurrences of ';' and '|' with ',' in the ion columns, keeping original if not found\n",
    "\n",
    "df[ion_columns] = df[ion_columns].map(\n",
    "    lambda x: str(x).replace(';', ',').replace('|', ',') if pd.notna(x) else x\n",
    ")\n",
    "\n",
    "# Continue with other processing or save the DataFrame as needed\n",
    "\n",
    "# print(df[ion_columns].head())\n",
    "\n",
    "\n",
    "### create sites column\n",
    "\n",
    "# Function to extract the site from the column name\n",
    "def get_site(column_name):\n",
    "    # Extract the site part from the column name\n",
    "    site = column_name.split('_')[3]  # 'a', 'b', or 'c' will be at index 3\n",
    "    return site\n",
    "\n",
    "# # Create a new 'site' column for ions and coefficients\n",
    "# # Loop through ion columns and assign the site based on the column name\n",
    "# ion_columns = [col for col in df.columns if 'Perovskite_composition' in col and 'ions' in col]\n",
    "# coefficient_columns = [col for col in df.columns if 'Perovskite_composition' in col and 'coefficients' in col]\n",
    "\n",
    "\n",
    "# # For each ion column, create a new site column\n",
    "# site_mapping = {}\n",
    "\n",
    "# for ion_col, coeff_col in zip(ion_columns, coefficient_columns):\n",
    "#     site = get_site(ion_col)  # Extract site from ion column\n",
    "#     site_mapping[ion_col] = site\n",
    "#     site_mapping[coeff_col] = site\n",
    "\n",
    "# # Now apply the new site to a new 'site' column\n",
    "# df['site'] = [site_mapping[col] for col in df[ion_columns].columns if 'ions' in col]\n",
    "\n",
    "# print(df['site'])\n",
    "\n",
    "# combine a b and c ions and coefficients in 1 column \n",
    "\n",
    "df['combined_ions'] = df.apply(lambda row: f\"{row['Perovskite_composition_a_ions']},{row['Perovskite_composition_b_ions']},{row['Perovskite_composition_c_ions']}\", axis=1)\n",
    "df['combined_coefficients'] = df.apply(lambda row: f\"{row['Perovskite_composition_a_ions_coefficients']},{row['Perovskite_composition_b_ions_coefficients']},{row['Perovskite_composition_c_ions_coefficients']}\", axis=1)\n",
    "\n",
    "print(df[['combined_ions', 'combined_coefficients']].head())\n",
    "\n",
    "# Save the updated DataFrame to a CSV file\n",
    "output_file = \"combined_ions_dataset.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"DataFrame with combined columns saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  combined_ions combined_coefficients           site\n",
      "0       Cs,Sn,I                 1,1,3          a,b,c\n",
      "1   Cs,Sn,Br, I          1,1,0.3, 2.7  a,b,c,Unknown\n",
      "2   Cs,Sn,Br, I          1,1,1.5, 1.5  a,b,c,Unknown\n",
      "3   Cs,Sn,Br, I          1,1,2.7, 0.3  a,b,c,Unknown\n",
      "4      Cs,Sn,Br                 1,1,3          a,b,c\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the site mapping based on original column names\n",
    "site_mapping = {\n",
    "    'Perovskite_composition_a_ions': 'a',\n",
    "    'Perovskite_composition_b_ions': 'b',\n",
    "    'Perovskite_composition_c_ions': 'c',\n",
    "    'Perovskite_composition_a_ions_coefficients': 'a',\n",
    "    'Perovskite_composition_b_ions_coefficients': 'b',\n",
    "    'Perovskite_composition_c_ions_coefficients': 'c'\n",
    "}\n",
    "\n",
    "# Function to assign site based on the original columns\n",
    "def assign_site(row):\n",
    "    # Split the ions and coefficients into lists\n",
    "    ions = row['combined_ions'].split(',')\n",
    "    coefficients = row['combined_coefficients'].split(',')\n",
    "    \n",
    "    # Create a list for sites to store the corresponding site for each ion/coeff\n",
    "    sites = []\n",
    "    \n",
    "    # Iterate through the ions and coefficients\n",
    "    for ion, coeff in zip(ions, coefficients):\n",
    "        # Determine which site this ion and coefficient belong to\n",
    "        if ion in df['Perovskite_composition_a_ions'].values:\n",
    "            sites.append('a')\n",
    "        elif ion in df['Perovskite_composition_b_ions'].values:\n",
    "            sites.append('b')\n",
    "        elif ion in df['Perovskite_composition_c_ions'].values:\n",
    "            sites.append('c')\n",
    "        else:\n",
    "            sites.append('Unknown')  # If not found, mark as unknown\n",
    "\n",
    "    # Return the sites as a comma-separated string\n",
    "    return ','.join(sites)\n",
    "\n",
    "# Apply this function to the dataframe\n",
    "df['site'] = df.apply(assign_site, axis=1)\n",
    "\n",
    "# Print the updated dataframe\n",
    "print(df[['combined_ions', 'combined_coefficients', 'site']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
